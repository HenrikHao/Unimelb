{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName('ReadCSV').getOrCreate()\n",
    "\n",
    "# Read all CSV files in a directory\n",
    "parquet_directory_path = '../data/development/'\n",
    "data = spark.read.parquet(parquet_directory_path, header=True, inferSchema=True)\n",
    "\n",
    "df = data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = df['item_id'].unique()\n",
    "item_id_to_index = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "df['item_idx'] = df['item_id'].map(item_id_to_index)\n",
    "df = df.astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "random_seed = 25\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, item_id_mapping, label_mapping):\n",
    "        self.user_ids = df['user_id'].unique()\n",
    "        self.user_data = []\n",
    "        for user_id in self.user_ids:\n",
    "            user_df = df[df['user_id'] == user_id]\n",
    "            item_ids = user_df['item_id'].map(item_id_mapping).values\n",
    "            labels = user_df['ratings_discretized'].values\n",
    "            other_features = user_df[['istrack', 'isalbum', 'isartist', 'isgenre']].values.astype(float)\n",
    "            self.user_data.append((torch.tensor(item_ids, dtype=torch.long),\n",
    "                                   torch.tensor(other_features, dtype=torch.float),\n",
    "                                   torch.tensor(labels, dtype=torch.long)))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.user_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_ids, other_features, labels = self.user_data[idx]\n",
    "        length = len(item_ids)\n",
    "        return item_ids, other_features, labels, length\n",
    "\n",
    "\n",
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model, device=device)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(pos * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.encoding[:, :seq_len, :]\n",
    "\n",
    "\n",
    "# Transformer-based Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_items, hidden_size, num_layers, num_heads, dropout_rate, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=hidden_size, padding_idx=0)\n",
    "        self.pos_encoder = PositionalEncoding(hidden_size)\n",
    "        \n",
    "        # Transformer Encoder Layer\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=132, nhead=num_heads, dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Final linear layer for classification\n",
    "        self.fc = nn.Linear(132, num_classes)\n",
    "\n",
    "    def forward(self, item_ids, other_features, lengths):\n",
    "        # Embedding and positional encoding\n",
    "        embeddings = self.embedding(item_ids)  # [batch_size, seq_len, embedding_dim]\n",
    "        embeddings = self.pos_encoder(embeddings)\n",
    "        transformer_input = torch.cat((embeddings, other_features), dim=2)\n",
    "        \n",
    "        # Transformer expects input of shape [seq_len, batch_size, d_model]\n",
    "        transformer_input = transformer_input.permute(1, 0, 2)\n",
    "        transformer_output = self.transformer_encoder(transformer_input)\n",
    "\n",
    "        # Revert shape to [batch_size, seq_len, hidden_size]\n",
    "        transformer_output = transformer_output.permute(1, 0, 2)\n",
    "        outputs = self.fc(transformer_output) \n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Modify the training and nested cross-validation process\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "    num_epochs = 100\n",
    "    model.to(device)\n",
    "    num_classes = model.fc.out_features\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for item_ids, features, labels, lengths in train_loader:\n",
    "            item_ids, features, labels, lengths = item_ids.to(device), features.to(device), labels.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(item_ids, features, lengths)\n",
    "            labels_flat = labels.view(-1)\n",
    "            outputs_flat = outputs.view(-1, num_classes)\n",
    "            mask = labels_flat != -1\n",
    "            loss = criterion(outputs_flat[mask], labels_flat[mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Training Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "        softmax_probs = []\n",
    "        with torch.no_grad():\n",
    "            for item_ids, features, labels, lengths in val_loader:\n",
    "                item_ids, features, labels, lengths = item_ids.to(device), features.to(device), labels.to(device), lengths.to(device)\n",
    "                outputs = model(item_ids, features, lengths)\n",
    "                labels_flat = labels.view(-1)\n",
    "                outputs_flat = outputs.view(-1, num_classes)\n",
    "                mask = labels_flat != -1\n",
    "                loss = criterion(outputs_flat[mask], labels_flat[mask])\n",
    "                val_loss += loss.item()\n",
    "                softmax_output = F.softmax(outputs_flat[mask], dim=1)\n",
    "                softmax_probs.extend(softmax_output.cpu().tolist())\n",
    "                _, preds = torch.max(outputs_flat[mask], dim=1)\n",
    "                val_labels.extend(labels_flat[mask].cpu().tolist())\n",
    "                val_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"        Validation Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "    return accuracy, (val_labels, val_preds, softmax_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested cross-validation function using Transformer model\n",
    "def nested_cross_validation(df: pd.DataFrame, n_outer: int, n_inner: int):\n",
    "    results_per_outer = []\n",
    "\n",
    "    # Create item_id and label mappings\n",
    "    unique_item_ids = df['item_id'].unique()\n",
    "    item_id_mapping = {item_id: idx + 1 for idx, item_id in enumerate(unique_item_ids)}  # +1 ensures padding_idx=0\n",
    "    num_items = len(unique_item_ids) + 1  # Padding index\n",
    "\n",
    "    unique_labels = df['ratings_discretized'].unique()\n",
    "    label_mapping = {label: idx for idx, label in enumerate(sorted(unique_labels))}\n",
    "    num_classes = len(unique_labels)\n",
    "\n",
    "    outer_folds = split_df_into_folds(df, n_outer)\n",
    "    for outer_idx, outer_fold in enumerate(outer_folds):\n",
    "        print(f\"Outer Fold {outer_idx + 1}/{n_outer}\")\n",
    "        outer_train_data = df[~df['user_id'].isin(outer_fold['user_id'])]\n",
    "        outer_val_data = outer_fold\n",
    "\n",
    "        best_inner_accuracy = 0\n",
    "        best_params = None\n",
    "\n",
    "        # Inner loop for hyperparameter tuning\n",
    "        for hidden_size in params_to_tune['hidden_size']:\n",
    "            for num_layers in params_to_tune['num_layers']:\n",
    "                for num_heads in params_to_tune['num_heads']:\n",
    "                    for dropout_rate in params_to_tune['dropout_rate']:\n",
    "                        inner_accuracies = []\n",
    "                        inner_folds = split_df_into_folds(outer_train_data, n_inner)\n",
    "                        print(f\"  Tuning: hidden_size={hidden_size}, num_layers={num_layers}, num_heads={num_heads}, dropout_rate={dropout_rate}\")\n",
    "                        for inner_idx, inner_fold in enumerate(inner_folds):\n",
    "                            print(f\"    Inner Fold {inner_idx + 1}/{n_inner}\")\n",
    "                            inner_train_data = outer_train_data[~outer_train_data['user_id'].isin(inner_fold['user_id'])]\n",
    "                            inner_val_data = inner_fold\n",
    "\n",
    "                            train_dataset = CustomDataset(inner_train_data, item_id_mapping, label_mapping)\n",
    "                            val_dataset = CustomDataset(inner_val_data, item_id_mapping, label_mapping)\n",
    "\n",
    "                            train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "                            val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "                            # Initialize the Transformer model\n",
    "                            model = TransformerModel(\n",
    "                                num_items=num_items,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_layers,\n",
    "                                num_heads=num_heads,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                num_classes=num_classes\n",
    "                            )\n",
    "\n",
    "                            criterion = nn.CrossEntropyLoss()\n",
    "                            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                            # Train and validate the model\n",
    "                            accuracy, _ = train_and_validate(model, train_loader, val_loader, criterion, optimizer)\n",
    "                            print(f\"    Accuracy: {accuracy:.4f}\")\n",
    "                            inner_accuracies.append(accuracy)\n",
    "                        \n",
    "                        avg_inner_accuracy = sum(inner_accuracies) / len(inner_accuracies)\n",
    "                        print(f\"  Average Inner Accuracy for hyperparameters: {avg_inner_accuracy:.4f}\")\n",
    "                        if avg_inner_accuracy > best_inner_accuracy:\n",
    "                            best_inner_accuracy = avg_inner_accuracy\n",
    "                            best_params = {\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'num_layers': num_layers,\n",
    "                                'num_heads': num_heads,\n",
    "                                'dropout_rate': dropout_rate\n",
    "                            }\n",
    "\n",
    "        print(f\"Best hyperparameters for Outer Fold {outer_idx + 1}: {best_params}\")\n",
    "\n",
    "        # Use the best hyperparameters to train on the outer fold\n",
    "        train_dataset = CustomDataset(outer_train_data, item_id_mapping, label_mapping)\n",
    "        val_dataset = CustomDataset(outer_val_data, item_id_mapping, label_mapping)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        # Initialize the Transformer model with the best parameters\n",
    "        model = TransformerModel(\n",
    "            num_items=num_items,\n",
    "            hidden_size=best_params['hidden_size'],\n",
    "            num_layers=best_params['num_layers'],\n",
    "            num_heads=best_params['num_heads'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train and validate the model on the outer fold\n",
    "        outer_accuracy, (val_labels, val_preds, val_softmax_probs) = train_and_validate(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "        # Store true labels, predictions, and softmax probabilities for each outer fold\n",
    "        results_per_outer.append((val_labels, val_preds, val_softmax_probs))\n",
    "        print(f\"  Outer Fold Accuracy: {outer_accuracy:.4f}\")\n",
    "\n",
    "    return results_per_outer\n",
    "\n",
    "\n",
    "# Parameter grid for tuning\n",
    "params_to_tune = {\n",
    "    'hidden_size': [128], \n",
    "    'num_layers': [2, 4],  \n",
    "    'num_heads': [2, 4], \n",
    "    'dropout_rate': [0.2]  \n",
    "}\n",
    "\n",
    "# Function to split the DataFrame by user IDs into folds\n",
    "def split_df_into_folds(df: pd.DataFrame, n_fold: int) -> List[pd.DataFrame]:\n",
    "    unique_user_ids = df['user_id'].unique().tolist()\n",
    "    random.shuffle(unique_user_ids)\n",
    "    user_id_chunks = [unique_user_ids[i::n_fold] for i in range(n_fold)]\n",
    "    folds = []\n",
    "    for chunk in user_id_chunks:\n",
    "        fold_df = df[df['user_id'].isin(chunk)]\n",
    "        folds.append(fold_df)\n",
    "    return folds\n",
    "\n",
    "# Example run of the nested cross-validation\n",
    "results = nested_cross_validation(df, n_outer=20, n_inner=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot combined ROC curve across all folds\n",
    "def plot_combined_roc_curve(results_per_outer, num_classes):\n",
    "    all_labels = []\n",
    "    all_softmax_probs = []\n",
    "\n",
    "    # Collect all labels and softmax probabilities across folds\n",
    "    for val_labels, _, val_softmax_probs in results_per_outer:\n",
    "        all_labels.extend(val_labels)\n",
    "        all_softmax_probs.extend(val_softmax_probs)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # Binarize the true labels for each class\n",
    "    for i in range(num_classes):\n",
    "        # One-vs-all ROC curve for class i\n",
    "        fpr[i], tpr[i], _ = roc_curve([1 if label == i else 0 for label in all_labels],\n",
    "                                      [prob[i] for prob in all_softmax_probs])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC curve for each class\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Rating Class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('One-vs-All ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "num_classes = 3\n",
    "plot_combined_roc_curve(results, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(results_per_outer, num_classes):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    # Collect all true labels and predictions across folds\n",
    "    for val_labels, val_preds, _ in results_per_outer:\n",
    "        all_labels.extend(val_labels)\n",
    "        all_preds.extend(val_preds)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "\n",
    "    # Plotting the confusion matrix using seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Low', 'Medium', 'High'], yticklabels=['Low', 'Medium', 'High'])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "num_classes = 3\n",
    "plot_confusion_matrix(results, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate mean and variance of accuracy, precision, recall, and F1\n",
    "def calculate_metrics_mean_and_variance(results_per_outer, average='macro'):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "\n",
    "    # Extract metrics from each fold\n",
    "    for val_labels, val_preds, _ in results_per_outer:\n",
    "        # Calculate accuracy for each fold\n",
    "        accuracy = accuracy_score(val_labels, val_preds)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Calculate precision, recall, and F1 for each fold, handling undefined metrics with zero_division=0\n",
    "        precision = precision_score(val_labels, val_preds, average=average, zero_division=0)\n",
    "        recall = recall_score(val_labels, val_preds, average=average, zero_division=0)\n",
    "        f1 = f1_score(val_labels, val_preds, average=average, zero_division=0)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    # Calculate mean and variance (std^2) for each metric\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    variance_accuracy = np.var(accuracies)\n",
    "\n",
    "    mean_precision = np.mean(precisions)\n",
    "    variance_precision = np.var(precisions)\n",
    "\n",
    "    mean_recall = np.mean(recalls)\n",
    "    variance_recall = np.var(recalls)\n",
    "\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    variance_f1 = np.var(f1s)\n",
    "\n",
    "    return {\n",
    "        'mean_accuracy': mean_accuracy, 'variance_accuracy': variance_accuracy,\n",
    "        'mean_precision': mean_precision, 'variance_precision': variance_precision,\n",
    "        'mean_recall': mean_recall, 'variance_recall': variance_recall,\n",
    "        'mean_f1': mean_f1, 'variance_f1': variance_f1\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "metrics = calculate_metrics_mean_and_variance(results, average='macro')\n",
    "print(f\"Mean Accuracy: {metrics['mean_accuracy']:.4f}, Variance (std^2): {metrics['variance_accuracy']:.4f}\")\n",
    "print(f\"Mean Precision: {metrics['mean_precision']:.4f}, Variance (std^2): {metrics['variance_precision']:.4f}\")\n",
    "print(f\"Mean Recall: {metrics['mean_recall']:.4f}, Variance (std^2): {metrics['variance_recall']:.4f}\")\n",
    "print(f\"Mean F1: {metrics['mean_f1']:.4f}, Variance (std^2): {metrics['variance_f1']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "imsize = 224\n",
    "image_dir = '../train/'\n",
    "metadata = pd.read_csv('../train.csv')\n",
    "metadata['filename'] = metadata['id'].apply(lambda x: f\"{image_dir}{x}.jpg\")\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 5, 6, 4, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['stable_height'].unique() # six label in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_seed = 25\n",
    "random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentataion, only apply to the training set\n",
    "def preprocess(filepath, label):\n",
    "    image = tf.io.read_file(filepath) # load file\n",
    "    image = tf.image.decode_jpeg(image, channels=3) # decode it into a tensor\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = (image - 127.5) / 127.5\n",
    "    return image, label - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augementation on training set and normalize the validation set\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_df['filename'], train_df['stable_height']))\n",
    "train_ds = train_ds.map(preprocess).batch(32).shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_df['filename'], val_df['stable_height']))\n",
    "val_ds = val_ds.map(preprocess).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape:  (15, 224, 224, 3)\n",
      "Label batch shape:  (15,)\n",
      "Labels:  tf.Tensor([4 2 4 2 2 0 0 3 2 0 2 0 3 1 5], shape=(15,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 16:18:37.037382: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):  # Just take one batch, check the info \n",
    "    print(\"Image batch shape: \", images.shape)\n",
    "    print(\"Label batch shape: \", labels.shape)\n",
    "    print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729206610.064372   75967 service.cc:146] XLA service 0x7f3ff0002d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729206610.064427   75967 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "2024-10-18 10:10:11.346703: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-18 10:10:20.140857: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45017', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2024-10-18 10:10:42.851021: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_76', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1729206643.188393   75967 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 230ms/step - accuracy: 0.2348 - loss: 1.8623 - val_accuracy: 0.2415 - val_loss: 3.8356 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - accuracy: 0.3409 - loss: 1.4816 - val_accuracy: 0.2415 - val_loss: 1.9192 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - accuracy: 0.4356 - loss: 1.3290 - val_accuracy: 0.2396 - val_loss: 1.9339 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - accuracy: 0.5142 - loss: 1.1795 - val_accuracy: 0.3691 - val_loss: 1.5799 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - accuracy: 0.5657 - loss: 1.0618 - val_accuracy: 0.4772 - val_loss: 1.3806 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - accuracy: 0.6228 - loss: 0.9674 - val_accuracy: 0.4134 - val_loss: 1.4382 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - accuracy: 0.6968 - loss: 0.8141 - val_accuracy: 0.5339 - val_loss: 1.3255 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - accuracy: 0.7346 - loss: 0.7027 - val_accuracy: 0.4375 - val_loss: 1.6019 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 206ms/step - accuracy: 0.7809 - loss: 0.5762 - val_accuracy: 0.5365 - val_loss: 1.4092 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 206ms/step - accuracy: 0.8226 - loss: 0.4902 - val_accuracy: 0.5150 - val_loss: 1.7528 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 206ms/step - accuracy: 0.8998 - loss: 0.2907 - val_accuracy: 0.5560 - val_loss: 1.6117 - learning_rate: 2.5000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - accuracy: 0.9702 - loss: 0.0987 - val_accuracy: 0.5540 - val_loss: 1.9460 - learning_rate: 2.5000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - accuracy: 0.9784 - loss: 0.0678 - val_accuracy: 0.5514 - val_loss: 2.2108 - learning_rate: 2.5000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 205ms/step - accuracy: 0.9890 - loss: 0.0429 - val_accuracy: 0.5645 - val_loss: 2.2260 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet152, ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Load ResNet-152 or ResNet-50 here pre-trained on ImageNet without the top layer\n",
    "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(imsize, imsize, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True \n",
    "\n",
    "# Add new layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate scheduling\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model with both callbacks\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../model/resnet152.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
